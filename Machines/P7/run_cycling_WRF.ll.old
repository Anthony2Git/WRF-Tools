#!/bin/bash
# LoadLeveler submission script for SciNet P7
# Specifies the name of the shell to use for the job
# @ shell = /bin/bash 
##=====================================
# @ job_name = max-ctrl-2100_WRF
# @ wall_clock_limit = 48:00:00
# @ node = 1
# @ tasks_per_node = 128
# @ notification = error
# @ output = $(job_name).$(jobid).out
# @ error = $(job_name).$(jobid).out
# @ environment = $NEXTSTEP; $NOWPS; MP_INFOLEVEL=1; \
#                 MP_USE_BULK_XFER=yes; MP_BULK_MIN_MSG_SIZE=64K; \
#                 MP_EAGER_LIMIT=64K; LAPI_DEBUG_ENABLE_AFFINITY=no; \
#                 MP_TASK_AFFINITY=CPU:1; MP_BINDPROC=yes
# @ job_type = parallel
# @ class = verylong
##=====================================
## this is necessary in order to avoid core dumps for batch files
## which can cause the system to be overloaded
# ulimits
# @ core_limit = 0
##=====================================
# @ queue


## machine specific job settings
export NODES=1 # number of nodes (necessary for TCS threading setup)
export WAITFORWPS='WAIT' # stay on compute node until WPS for next step finished, in order to submit next WRF job
# get LoadLeveler names (needed for folder names)
export JOBNAME="${LOADL_JOB_NAME}"
export INIDIR="${LOADL_STEP_INITDIR}" # experiment root (launch directory)
# run scripts
export WRFSCRIPT="run_cycling_WRF.ll" # WRF suffix assumed
export WPSSCRIPT="run_cycling_WPS.pbs" # WRF suffix assumed, WPS suffix substituted: ${JOBNAME%_WRF}_WPS
