#!/bin/bash

## queue/PBS settings
#PBS -l nodes=1:m128g:ppn=16
# batch queue: nodes=4:m32g:ppn=8
# largemem queue: nodes=1:m128g:ppn=16
#PBS -l walltime=48:00:00
# merge standard error and output stream
#PBS -j oe
#PBS -o $PBS_JOBNAME.$PBS_JOBID.out
# send email if abort (nbae)
#PBS -M aerler@atmosp.physics.utoronto.ca
#PBS -m ae
# job name
#PBS -N gpl_cesmavg_all
###PBS -W depend=afterok:$PBS_JOBID
## submit to queue (NB: this has to be the last PBS line!)
# batch (default), debug, largemem
#PBS -q largemem

# load modules (we need to load the netcdf module in order to use it in Python)
echo
module purge
module load intel/13.1.1 gcc/4.8.1 hdf5/187-v18-serial-intel netcdf/4.1.3_hdf5_serial-intel gnu-parallel/20130422  
module load python/2.7.3 gdal/1.9.2 extras/64_6.4 ncl/6.2.0 gsl/1.13-intel udunits/2.1.11 nco/4.3.2-intel
module load Xlibraries/X11-64 ImageMagick/6.6.7
module list
echo

#shopt -s extglob

# default settings
JOBNAME=${PBS_JOBNAME:-'test'}
WORKDIR=${PBS_O_WORKDIR:-"${PWD}"}
CMDFILE=${CMDFILE:-"${WORKDIR}/cmdfile.${JOBNAME}"}
LOGFILE=${LOGFILE:-"${WORKDIR}/logfile.${JOBNAME}"}
rm -f "${CMDFILE}" "${LOGFILE}" # clean...
THREADS=${THREADS:-4} # GNU Parallel threads
# N.B.: some operations require significant amounts of memory, so that 8 threads is too much

#SRCR='/reserved1/p/peltier/marcdo/FromHpss' # Marc's folder on reserved (default)
#SRCR='/scratch/p/peltier/marcdo/archive/' # Marc's folder on scratch
export CCA=${CAA:-"/reserved1/p/peltier/aerler//CESM/archive/"} # my CESM archive folder as source; used in several scripts

# just for tests
#RUNS='seaice-3r-hf/'
#PERIODS='5' # averaging periods
# historical runs and projections
RUNS=${RUNS:-'h[abc]b20trcn1x1/ tb20trcn1x1/ h[abct]brcp85cn1x1/ h[abct]brcp85cn1x1d/ seaice-[35]r-hf/ seaice-5r-hfd/'}
PERIODS=${PERIODS:-'5 10 15'} # averaging periods
# cesm_average settings
CVDP=${CVDP:-'FALSE'} # Climate Variability Diagnostics Package (set to CVDP)
REFCLM=${REFCLM:-'HISTORICAL'} # climatology that is used to remove annual cycle in CVDP" HISTORICAL, PERIOD 
DIAG=${DIAG:-'FALSE'} # Climatology Diagnostics Package (set to DIAG)
CONCAT=${CONCAT:-'FALSE'} # concatenate monthly files (set to CONCAT)
AVERAGE=${AVERAGE:-'FALSE'} # compute climatologies (set to AVERAGE)
OVERWRITE=${OVERWRITE:-'FALSE'} # recompute or not
FILETYPES=${FILETYPES:-'atm lnd ice'} # file types to process

# feedback
cd "${WORKDIR}"
echo ''
echo 'Processing CESM experiments:'
echo ''
ls -d $RUNS
echo ''
echo "Computing AMWG Diagnostics: ${DIAG}"
echo "Concatenate Output: ${CONCAT}"
if [[ "${CONCAT}" == 'CONCAT' ]] || [[ "${AVERAGE}" == 'AVERAGE' ]]; then echo "File Types: ${FILETYPES}"; fi
echo "Average Output: ${AVERAGE}"
if [[ "${AVERAGE}" == 'AVERAGE' ]]; then echo "Averaging Periods: ${PERIODS}"; fi
echo "Computing CVDP: ${CVDP}"
echo "Overwriting Files: ${OVERWRITE}"
echo


## generate command file for GNU Parallel
# root directory
cd "${WORKDIR}"
touch "${CMDFILE}.diag" "${CMDFILE}.concat" "${CMDFILE}.average" "${CMDFILE}.cvdp" 
# loop over runs
for RUN in $RUNS
  do
    echo
    # set up folders
    RUN=${RUN%/} # remove trailing slash, if any
    RUNDIR="${WORKDIR}/${RUN}/" # extract highest order folder name as run name
    AVGDIR="${RUNDIR}/cesmavg/" # subfolder for averages
    echo "   ***   Processing $RUN   ***   "
    echo "   ($RUNDIR)" 
    cd "${RUNDIR}"

    # determine period and other meta data from name
    if [[ "$RUN" == *20tr* ]]; then SPRD='1979'; EPRD='1993'; HREF='OBS'; 
    elif [[ "$RUN" == *rcp* ]]; then 
      if [[ "$RUN" == htbrcp* ]]; then HREF="tb20tr${RUN#*rcp??}" # special case
      else HREF="${RUN%rcp*}20tr${RUN#*rcp??}"; fi # guess name of historical simulation
      if [[ "$RUN" == *d ]]; then SPRD='2085'; EPRD='2099'; HREF=${HREF%d}; 
      else SPRD='2045'; EPRD='2059'; fi
    elif [[ "$RUN" == seaice-5r-hfd ]]; then SPRD='2085'; EPRD='2099'; HREF='tb20trcn1x1'
    elif [[ "$RUN" == seaice-5r-hf ]]; then SPRD='2045'; EPRD='2059'; HREF='tb20trcn1x1'
    elif [[ "$RUN" == seaice-*-hf ]]; then SPRD='2045'; EPRD='2059'; HREF='tb20trcn1x1'
    else echo "ERROR: No settings found for experiment '$RUN' - aborting!"; exit 1     
    fi # $RUN settings
    EEPRD=$(( $EPRD +1 )) # different convention in climatology file
    case $SPRD in # ensemble control
        1979) CREF='tb20trcn1x1'; P_CLIM_FILE="$CCA/ens20trcn1x1/cesmavg/cesmatm_clim_${SPRD}-${EEPRD}.nc";;
        2045) CREF='htbrcp85cn1x1'; P_CLIM_FILE="$CCA/ensrcp85cn1x1/cesmavg/cesmatm_clim_${SPRD}-${EEPRD}.nc";;
        2085) CREF='htbrcp85cn1x1d'; P_CLIM_FILE="$CCA/ensrcp85cn1x1d/cesmavg/cesmatm_clim_${SPRD}-${EEPRD}.nc";;
    esac
    H_CLIM_FILE="$CCA/ens20trcn1x1/cesmavg/cesmatm_clim_1979-1994.nc" # historical climatology
    HPRD='1979'; CPRD=$SPRD # begin of reference periods: hsitorical and current/control
    if [[ "$RUN" == "$CREF" ]]; then CREF=''; CPRD=''; fi # special case: can't compare to itself
    # save meta info in script for later reference
    echo "RUN='${RUN}'; SPRD='${SPRD}'; EPRD='${EPRD}'; HREF='${HREF}'; HPRD='${RPRD}'; CREF='${CREF}'; CPRD='${CPRD}'" > exp_info.sh     
    #source exp_info.sh # defines RUN, SPRD, EPRD, HREF, HPRD, CREF, and CPRD for each run
    # N.B.: To process any experiment, simply add a meta data/settings file named 'exp_info.sh' to to the
    #       experiment's root folder, where the above parameters are defined (as shell environment variables); 
    #       the script is then sourced at this point, and parameters are set.
    NPRD=$(( 1 + $EPRD - $SPRD )) # length of period; end year is inclusive
    # calculate periods
    PRDS='' # clear variable
    for PRD in $PERIODS; do
      if [ $PRD -le $NPRD ]; then PRDS="${PRDS} ${SPRD}-$(( $SPRD + $PRD ))"; fi
    done # loop over start dates and periods

		
    ## Climatology Diagnostics Package (AMWG)
		if [[ "${DIAG}" == 'DIAG' ]]
		  then
		    mkdir -p "$RUNDIR/diag/" # make sure destination folder exists
        ln -sf "${MODEL_ROOT}/WRF Tools/Scripts/GPC/run_amwg_diag.csh" # link AMWG script (CSH)
        # current/control reference
        if [[ -n "$HREF" ]]; then 
	        if [[ "$HREF" == 'OBS' ]]; then DIAGTAR="$RUNDIR/diag/$RUN-obs.tar"
	        else DIAGTAR="$RUNDIR/diag/$RUN-$HREF.tar"; fi
	        if [ ! -f "$DIAGTAR" ] || [[ "$OVERWRITE" == 'OVERWRITE' ]]; then
			      echo "   Running AMWG Diagnostics: $DIAGTAR"
	          echo "cd $RUNDIR; csh -ef run_amwg_diag.csh $RUN $SPRD $NPRD $HREF $HPRD &> $RUNDIR/diag_hist.log" >> "${CMDFILE}.diag"
			    else
	          echo "   Skipping AMWG Diagnostics: $DIAGTAR"
	        fi # if actually running
        fi # $HREF
        # current/control reference
        if [[ -n "$CREF" ]]; then 
          if [[ "$CREF" == 'OBS' ]]; then DIAGTAR="$RUNDIR/diag/$RUN-obs.tar"
          else DIAGTAR="$RUNDIR/diag/$RUN-$CREF.tar"; fi
          if [ ! -f "$DIAGTAR" ] || [[ "$OVERWRITE" == 'OVERWRITE' ]]; then
            echo "   Running AMWG Diagnostics: $DIAGTAR"
            echo "cd $RUNDIR; csh -ef run_amwg_diag.csh $RUN $SPRD $NPRD $CREF $CPRD &> $RUNDIR/diag_ctrl.log" >> "${CMDFILE}.diag"
          else
            echo "   Skipping AMWG Diagnostics: $DIAGTAR"
          fi # if actually running
        fi # $CREF
		fi # $DIAG 
		   
		   
    # loop iver file types
		for FILETYPE in $FILETYPES
      do        
        
        ## concatenate history files
		    if [[ "${CONCAT}" == 'CONCAT' ]]
          then
            mkdir -p "${AVGDIR}" # make sure destination folder exists
		        ## assemble time-series
				    case $FILETYPE in
				      atm) FILES="${RUNDIR}/${FILETYPE}/hist/${RUN}.cam2.h0";; 
				      lnd) FILES="${RUNDIR}/${FILETYPE}/hist/${RUN}.clm2.h0";; 
				      ice) FILES="${RUNDIR}/${FILETYPE}/hist/${RUN}.cice.h";; 
				    esac
            # list of proper years
            FILELIST=''
            for Y in $( seq $SPRD $EPRD ); do
              FILELIST="${FILELIST} ${FILES}.${Y}-??.nc"; done
				    # NCO command
				    NCOARGS="--netcdf4 --deflate 1" # use NetCDF4 compression
		        NCOOUT="${AVGDIR}/cesm${FILETYPE}_monthly.nc"
				    if [[ ! -e "${NCOOUT}" ]] || [[ "$OVERWRITE" == 'OVERWRITE' ]]; then
				      echo "   Concatenating: ${NCOOUT}"
		          echo "cd ${RUNDIR}; ncrcat $NCOARGS --output ${NCOOUT} --overwrite ${FILELIST} &> ${NCOOUT%.nc}.log" >> "${CMDFILE}.concat"
				    else
				      echo "   Skipping: ${NCOOUT}"
				    fi # if already file exits
        fi # $CONCAT


        ## compute climatologies (from monthly averages)
        if [[ "${AVERAGE}" == 'AVERAGE' ]]
          then
            mkdir -p "${AVGDIR}" # make sure destination folder exists
            ln -sf "${MODEL_ROOT}/WRF Tools/Python/average/cesm_average.py" # link averaging script
				    # loop over averaging periods
		        for PERIOD in $PRDS
		          do
		            ## compute averaged climatologies
		            # launch python script, save output in log file
		            PYAVGOUT="${AVGDIR}/cesm${FILETYPE}_clim_${PERIOD}.nc"
		            if [[ ! -f "$PYAVGOUT" ]] || [[ "$OVERWRITE" == 'OVERWRITE' ]]; then
		              echo "   Averaging: ${PYAVGOUT}"
			            echo "cd ${RUNDIR}; export PYAVG_FILETYPE=${FILETYPE}; python -u cesm_average.py ${PERIOD} &> ${PYAVGOUT%.nc}.log" >> "${CMDFILE}.average"
		            else
		              echo "   Skipping: ${PYAVGOUT}"
		            fi # if already file exits
		        done # for $PERIODS
        fi # $AVERAGE

    done # for $FILETYPES


    ## climate variability diagnostics (CVDP)
    if [[ "${CVDP}" == 'CVDP' ]]
      then
        mkdir -p "$RUNDIR/cvdp/" # make sure destination folder exists
        ln -sf "${MODEL_ROOT}/WRF Tools/NCL/CVDP/run_cvdp.sh" # link CVDP driver script
        #if [ -f "$RUNDIR/cvdp.log" ]; then CVDPOUT=$( grep -c 'The NCL driver script completed successfully' "$RUNDIR/cvdp.log" )
        #else CVDPOUT=0; fi # always run CVDP, if no logs are present
        if [ ! -f "$RUNDIR/cvdp/cvdp.tar" ] || [[ "$OVERWRITE" == 'OVERWRITE' ]]; then
          echo "   Running CVDP"
          rm -rf "$RUNDIR/cvdp/" 
          export TEST # TEST=True only generates namelists
          if [[ "$REFCLM" == 'HISTORICAL' ]]; then CLIMO="$H_CLIM_FILE"
          elif [[ "$REFCLM" == 'PERIOD' ]]; then CLIMO="$P_CLIM_FILE"
          fi # currently no other options
          echo "cd $RUNDIR; bash -e run_cvdp.sh $RUN $SPRD $EPRD $CLIMO &> $RUNDIR/cvdp.log" >> "${CMDFILE}.cvdp" 
        else
          echo "   Skipping CVDP"
        fi # if actually running
    fi # $CVDP
    

done # for $RUNS
echo 

# assemble command file (so that not all processes are accessing the same files at once)
cat "${CMDFILE}.diag" "${CMDFILE}.concat" "${CMDFILE}.average" "${CMDFILE}.cvdp" > "${CMDFILE}"
rm "${CMDFILE}.diag" "${CMDFILE}.concat" "${CMDFILE}.average" "${CMDFILE}.cvdp"

## execute GNU Parallel commands
#parallel -j $THREADS --joblog "${LOGFILE}" < "${CMDFILE}" # only for single-node execution
parallel --sshloginfile "$PBS_NODEFILE" --workdir "$PWD" \
          --env PYTHON_EGG_CACHE \
          #--env PYAVG_FILETYPE \ # probably not necessary, since explicitly set in command
         -j 8 --joblog "${LOGFILE}" < "${CMDFILE}"
ERR=$? # capture exit code

# clean up
echo
if [[ 0 == ${ERR} ]]
  then
    echo '   ***   All Jobs Completed Successfully!!!   ***   '
    rm "${CMDFILE}" "${LOGFILE}"
  else
    echo "  >>>   ERRORS DETECTED - EXIT CODE ${ERR}   <<<   " 
    echo "Inspect command and log files:"
    echo "   ${CMDFILE}"
    echo "   ${LOGFILE}"
    echo
    cat "${LOGFILE}"
fi # if $ERR
echo

# exit with gnuparallel exit code
exit ${ERR}
