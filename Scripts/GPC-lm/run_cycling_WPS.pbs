#!/bin/bash
#MOAB/Torque submission script for SciNet GPC

## queue/PBS settings
#PBS -l nodes=1:m128g:ppn=16
#PBS -l walltime=1:00:00
# merge standard error and output stream
#PBS -j oe
#PBS -o $PBS_JOBNAME.$PBS_JOBID.out
# send email if abort (nbae)
#PBS -M aerler@atmosp.physics.utoronto.ca
#PBS -m a
# job name
#PBS -N cycling_WPS
## submit to queue (NB: this has to be the last PBS line!)
# batch (default), debug, largemem
#PBS -q largemem

# check if $NEXTSTEP is set, and exit, if not
set -e # abort if anything goes wrong
if [[ -z "${NEXTSTEP}" ]]; then exit 1; fi
CURRENTSTEP="${NEXTSTEP}" # $NEXTSTEP will be overwritten

## job settings
export SCRIPTNAME="run_cycling_WPS.pbs" # WPS suffix assumed
export CLEARWDIR=0 # do not clear working director
# run configuration
export NODES=1 # only one for WPS!
export TASKS=16 # number of MPI task per node (Hpyerthreading?)
export THREADS=1 # number of OpenMP threads
# directory setup
export INIDIR="${PBS_O_WORKDIR}"
export RUNNAME="${CURRENTSTEP}" # step name, not job name! 
export WORKDIR="${INIDIR}/${RUNNAME}/"

# optional arguments $RUNPYWPS, $RUNREAL, $RAMIN, $RAMOUT
export RUNPYWPS=1
export RUNREAL=1
export RAMIN=1
export RAMOUT=1
# folders: $METDATA, $REALIN, $REALOUT
export METDATA="${INIDIR}/metgrid/" # to output metgrid data set "ldisk = True" in meta/namelist.py
export REALOUT="${WORKDIR}" # this should be default anyway


## setup environment
cd "${INIDIR}"
source setup_GPC-lm.sh # load machine-specific stuff


## begin job

# start timing
echo
echo '   ***   Start Time    ***   '
date
echo 

# prepare directory
cd "${INIDIR}"
./prepWorkDir.sh # don't remove working directory ($CLEARWDIR=0)

# run WPS driver script
cd "${INIDIR}"
./execWPS.sh

# copy driver script into work dir to signal completion
cp "${INIDIR}/${SCRIPTNAME}" "${WORKDIR}"

# end timing
echo
echo '    ***    End Time    *** '
date
echo
