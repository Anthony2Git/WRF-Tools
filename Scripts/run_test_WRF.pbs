#!/bin/bash
#MOAB/Torque submission script for SciNet GPC

## queue/PBS settings
#PBS -l nodes=16:qdr:ppn=8
#PBS -l walltime=4:00:00
#PBS -W x=nodesetisoptional:false
# std and error output
#PBS -j oe
#PBS -o $PBS_JOBNAME.$PBS_JOBID.out
##PBS -e $PBS_JOBNAME.$PBS_JOBID.err
# send email if abort (nbae)
#PBS -M aerler@atmosp.physics.utoronto.ca
#PBS -m ae
# assemble job name
#PBS -N test_WRF
# job dependency (this ${PBS_JOBNAME%_WRF}_WPS does not work)
#PBS -W depend:afterok:test_WPS
## submit to queue (NB: this has to be the last PBS line!)
# batch (default), debug, largemem
#PBS -q batch 

## job settings
SCRIPTNAME="run_${PBS_JOBNAME}.pbs" # WRF suffix assumed
# run configuration
export NODES=${PBS_NUM_NODES} # set in PBS section
export TASKS=16 # number of MPI task per node (Hpyerthreading!)
export THREADS=1 # number of OpenMP threads
# directory setup
export INIDIR="${PBS_O_WORKDIR}"
export RUNNAME="${PBS_JOBNAME%_*}" # strip WRF suffix
export WORKDIR="${INIDIR}/${RUNNAME}/"
export RAMDISK="/dev/shm/aerler/"

## real.exe settings
# optional arguments: $RUNREAL, $RAMIN, $RAMOUT
# folders: $REALIN, $REALOUT
# N.B.: RAMIN/OUT only works within a single node!

## WRF settings
# optional arguments: $RUNWRF, $GHG ($RAD, $LSM) 
export GHG='A2' # GHG emission scenario
# folders: $WRFIN, $WRFOUT, $TABLES
WRFIN="${WORKDIR}" 

## setup job environment
echo
hostname
uname
echo
echo "   ***   ${PBS_JOBNAME}   ***   "
echo


# load modules
module purge
module load intel intelmpi hdf5/187-v18-serial-intel netcdf/4.1.3_hdf5_serial-intel
#module load intel/12.1.3 intelmpi/4.0.3.008 hdf5/187-v18-serial-intel netcdf/4.1.3_hdf5_serial-intel
module list
# unlimit stack size (unfortunately necessary with WRF to prevent segmentation faults)
ulimit -s unlimited
# clear and (re-)create RAM disk folder
if [[ $RUNREAL == 1 ]] && [[ $RAMIN == 1 || $RAMOUT == 1 ]];then
	# N.B.: this only works, because default for all variables is 0 = "false".
	echo 'Creating RAM disk.'
	rm -rf "${RAMDISK}"
	mkdir -p "${RAMDISK}"
fi

# set up hybrid envionment: OpenMP and MPI (Intel)
#export KMP_AFFINITY=verbose,granularity=thread,compact
#export I_MPI_PIN_DOMAIN=omp
export I_MPI_DEBUG=1 # less output (currently no problems) 
# launch Intel hybrid (mpi/openmp) job
export HYBRIDRUN="mpirun -ppn ${TASKS} -np $((NODES*TASKS))" # only one node for WPS!


## begin job

# start timing
echo
echo '   ***   Start Time    ***   '
date
echo 

# clear and (re-)create job folder if neccessary
if [[ $RUNREAL == 1 ]] || [[ "${WRFIN}" != "${WORKDIR}" ]]; then
	# only delete folder if we are running real.exe or input data is coming from elsewhere
	echo 'Removing old working directory:' 
	echo "${WORKDIR}"
	rm -rf "${WORKDIR}"
	mkdir -p "${WORKDIR}"
fi
# copy driver script into work dir
cp "${INIDIR}/$SCRIPTNAME" "${WORKDIR}"
cp "${INIDIR}/execWRF.sh" "${WORKDIR}"

# run script
cd "${WORKDIR}"
./execWRF.sh
 
# end timing
echo
echo '    ***    End Time    *** '
date
echo
