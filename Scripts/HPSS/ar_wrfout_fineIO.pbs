#!/bin/bash
#MOAB/Torque archiving script for SciNet HPSS

## queue/PBS settings
# 72h is maximum for long queue, 1h for short
#PBS -l walltime=03:00:00
# merge standard error and output stream
#PBS -j oe
#PBS -o $PBS_JOBNAME.$PBS_JOBID.out
##PBS -e $PBS_JOBNAME.$PBS_JOBID.err
# send email if abort (nbae)
#PBS -M aerler@atmosp.physics.utoronto.ca
#PBS -m a
# job name
#PBS -N ar_test
## submit to queue (NB: this has to be the last PBS line!)
#PBS -q archive

#set -o pipefail # through error (in exit code) if pipe fails
trap "echo 'Job script not completed';exit 129" TERM INT
# Note that your initial directory in HPSS will be /archive/$(id -gn)/$(whoami)/

## definitions
# set $TAGS to determine, which file sets to archive
# operation to perform: CHECK, LIST, VERIFY, REMOVE, BACKUP, RETRIEVE
MODE=${MODE:-'BACKUP'} # default operation: 'BACKUP'
RMSRC=${RMSRC:-'NO'} # set to 'RMSRC' to actually perform deletion
VERIFY=${VERIFY:-'VERIFY'} # verify tarballs; can slow down operations significantly
GLOB=${GLOB:-'NO'} # globbing expressions in file names? see DATASET and INTERVAL
# N.B.: do not edit these variable; instead pass them as environment variables
DATASET=${DATASET:-'FULL_D12'} # default dataset: everything
INTERVAL=${INTERVAL:-'MONTHLY'} # default is monthly
# N.B.: the datasets are defined in PROCESSDATASET below
# data folder
DST=${DST:-"${ARCHIVE}/${PBS_O_WORKDIR#/*/${USER}/}/"} # replicate directory tree
# replace things like '/scratch/g/group/user/' with $ARCHIVE
INIDIR="${PBS_O_WORKDIR}"
WRFOUT="${INIDIR}/wrfout/" # output folder
SRC=${SRC:-"${WRFOUT}"} # where the data is (on disk)

# configure file according to archiving interval
if [[ "${INTERVAL}" == "YEARLY" ]]; then
  # use this filename pattern to infer list of $TAGS
  PATTERN='-01_wrf.tgz' # filename "${TAG}${PATTERN}": remove $PATTERN, keep $TAG
  # N.B.: this option will usually only be relevant for bulk jobs; using '-01' makes sure incomplete years are not omitted
  GLOB='GLOB' # use globbing expressions in filenames
  DATEGLOB='-[01][0-9]' # match all months (01-12)
elif [[ "${INTERVAL}" == "MONTHLY" ]]; then
  # use this filename pattern to infer list of $TAGS
  PATTERN='_wrf.tgz' # filename "${TAG}${PATTERN}": remove $PATTERN, keep $TAG
  GLOB='GLOB' # use globbing expressions in filenames
  DATEGLOB='' # actually no globbing necessary
fi # ${INTERVAL}

## function to check the contents of an HTAR archive
function CHECKHTAR () {
  local HTAR="${DST}/${1}" # archive file (absolute path on HPSS)
  local FILES=${2} # list of files that should be in the archive
  local QUIET="${3}" # suppress positive output (still print missing files!)
  local LIST=$( htar -vtf "${HTAR}" | awk '{print $7}' ) # column 7 are the file names
  local MISS=0 # missing file counter
  # evaluate globbing expression
  if [[ "${GLOB}" == 'GLOB' ]]; then
    FILES=$( ls -C ${FILES} ); fi
  # print expected archive contents
  if [[ "${QUIET}" != 'QUIET' ]]; then
    echo "${HTAR}   :::   ${FILES}"; fi # print feedback
  # loop over files in list and check presence in HTAR list
  for FILE in ${FILES}; do
    if [[ "${FILE}" != $( echo "${LIST}" | sed -n "/${FILE}/p" ) ]]; then
      if [[ ${MISS} == 0 ]]; then echo; fi # visually offset missing file list
      echo "WARNING: File ${FILE} missing in archive ${HTAR}"
      MISS=$(( ${MISS} + 1 ))
    fi
  done
  if [[ ${MISS} != 0 ]]; then echo; fi # visually offset missing file list
  # return number of missing files
  return ${MISS}
}

## function to list contents of HTAR archive
function LISTHTAR () {
  local HTAR="${DST}/${1}" # archive file (absolute path on HPSS)
  local MISS=0 # error code
  echo "${HTAR} ::: *" # print feedback
  # check if archive exists
  hsi -q ls "${HTAR}" &> /dev/null # quiet mode
  if [[ $? != 0 ]]; then
	echo "Warning: archive ${HTAR} does not exist."
	MISS=1
  else
    # list archive contents
	htar -tvf "${HTAR}" -Hcrc -Hverify=1
	MISS=$?
  fi
  # return exit code
  return ${MISS}
}

## function to verify contents of HTAR archive
function VERIFYHTAR () {
  local HTAR="${DST}/${1}" # archive file (absolute path on HPSS)
  local FILES=${2} # list of files that should be in the archive
  local QUIET="${3}" # suppress positive output (still print missing files!)
  local MISS=0 # error code
  # evaluate globbing expression
  if [[ "${GLOB}" == 'GLOB' ]]; then
    FILES=$( ls -C ${FILES} ); fi
  # print expected archive contents
  if [[ "${QUIET}" != 'QUIET' ]]; then
      echo "${HTAR}   :::   ${FILES}"; fi # print feedback
  # check if archive exists
  hsi -q ls "${HTAR}" &> /dev/null # quiet mode
  if [[ $? != 0 ]]; then
	echo "Warning: archive ${HTAR} does not exist."
	MISS=1
  else
    # verify archive contents
    if [[ "${VERIFY}" == 'VERIFY' ]]; then
      # evaluate globbing expression
      if [[ "${GLOB}" == 'GLOB' ]]; then
	htar -Kvf "${HTAR}" -Hcrc -Hverify=1 # verifying all files
	MISS=$?
      else
	htar -Kvf "${HTAR}" -Hcrc -Hverify=1 ${FILES}
	MISS=$?
      fi # $GLOB
    else
      # verify without verification...
      echo "Warning: verification is switched off - checking contents instead."
      CHECKHTAR "${1}" "${2}" 'QUIET' # check contents
      MISS=$?
    fi # $VERIFY
  fi
  # return exit code
  return ${MISS}
}

## function to remove source files of an HTAR archive
function REMOVEHTAR () {
  local HTAR="${DST}/${1}" # archive file (absolute path on HPSS)
  local FILES=${2} # list of files that should be in the archive
  local LIST=$( htar -vtf "${HTAR}" | awk '{print $7}' ) # column 7 are the file names
  local MISS=0 # missing file counter
  # check files on disk
  if [[ "${GLOB}" == 'GLOB' ]]; then
    # evaluate globbing expression
    FILES=$( ls -C ${FILES} )
  else # OR
    # check if any of the files still exist
    CNT=0; for F in "${FILES}"; do
      if [[ -e "${F}" ]]; then CNT=$(( CNT + 1 )); fi; done;
  fi # $GLOB
  # print expected archive contents
  echo "${HTAR}   ---   ${FILES}" # print feedback
  if [[ -n "${CNT}" ]] && [[ ${CNT} == 0 ]]; then
    echo '   >>> none of the files exist anymore - skipping this step!'
    echo '   (use the VERIFY operation to verify integrity of the archive)'
  else
    if [[ "${VERIFY}" == 'VERIFY' ]]; then
      # verify archive contents
      VERIFYHTAR "${1}" "${2}" 'QUIET'
      MISS=$?
    fi # $VERIFY
    if [[ $MISS == 0 ]]; then
      # loop over files in list and check presence in HTAR list
      for FILE in ${FILES}; do
	if [[ "${FILE}" == $( echo "${LIST}" | sed -n "/${FILE}/p" ) ]]; then
	  if [[ "${RMSRC}" == 'RMSRC' ]]; then # additional safety check
	    if [[ -e "${FILE}" ]]; then
	      echo "   >>> removing ${FILE}"
	      rm "${FILE}"
	    else echo "   ### ${FILE} does not exist"; fi
	  else
	    echo "   >>> would remove ${FILE}, if RMSRC='RMSRC' was set..."
	  fi # RMSRC
	else
	  if [[ ${MISS} == 0 ]]; then echo; fi # visually offset missing file list
	  echo "WARNING: File ${FILE} missing in archive ${HTAR}"
	  echo "   >>> not deleting ${FILE}"
	  MISS=$(( ${MISS} + 1 ))
	fi
      done
    else
      echo
      echo "   >>>   Cannot verify integrity of archive ${HTAR} - aborting!   <<<   "
      echo
      MISS=1
    fi
  fi
  # return number of missing files
  return ${MISS}
}

## function to create a new HTAR archive
function BACKUPHTAR () {
  local HTAR="${DST}/${1}" # archive file (absolute path on HPSS)
  local FILES=${2} #
  # evaluate globbing expression
  if [[ "${GLOB}" == 'GLOB' ]]; then
    FILES=$( ls -C ${FILES} ); fi # display output in columns (i.e. long lines)
  # check if archive already exists
  echo "${FILES}   >>>   ${HTAR}" # print feedback
  hsi -q ls "${HTAR}" &> /dev/null # quiet mode
  if [[ $? == 0 ]]; then
    echo "Warning: archive ${HTAR} already exists - checking contents."
    CHECKHTAR "${1}" "${2}" 'QUIET' # check contents
    if [[ $? == 0 ]]; then
      echo "   Archive OK, skipping backup..."
      return 0
    else
      echo "   Archive contents are different - removing old archive and creating new."
      hsi -q rm "${HTAR}"
    fi
  fi
  # create archive
  htar -cpf "${HTAR}" -Hcrc -Hverify=1 ${FILES}
  # verify contents
  if [[ "${VERIFY}" == 'VERIFY' ]]; then
    # verify archive contents
    echo "Verifying contents (not sure if this is necessary, but doesn't hurt.')"
    VERIFYHTAR "${1}" "${2}" 'QUIET'
    MISS=$?
  else
    # verify without verification...
    echo "Warning: verification is switched off - checking contents instead."
    CHECKHTAR "${1}" "${2}" 'QUIET' # check contents
    MISS=$?
  fi # $VERIFY
  # return results of verification
  return $?
}

## function to create a new HTAR archive
function RETRIEVEHTAR () {
  local HTAR="${DST}/${1}" # archive file (absolute path on HPSS)
  local FILES=${2} # list of files to extract
  local MISS=0 # exit code
  # evaluate globbing expression
  if [[ "${GLOB}" == 'GLOB' ]]; then
    FILES=$( ls -C ${FILES} ); fi
  echo "${HTAR}   >>>   ${FILES}" # print feedback
  # check if archive exists and verify integrity (VERIFYHTAR checks existence)
  if [[ "${VERIFY}" == 'VERIFY' ]]; then
    # verify archive contents
    echo "Verifying contents."
    VERIFYHTAR "${1}" "${2}" 'QUIET'
    MISS=$?
  else
    # verify without verification...
    echo "Warning: verification is switched off - checking contents instead."
    CHECKHTAR "${1}" "${2}" 'QUIET' # check contents
    MISS=$?
  fi # $VERIFY
  if [[ $MISS != 0 ]]; then
	echo "Warning: cannot verify archive ${HTAR} - aborting!"
  else
    echo "Archive ${HTAR} exists - contents OK."
    # evaluate globbing expression
    if [[ "${GLOB}" == 'GLOB' ]]; then
      # extract archive
      htar -xpmf "${HTAR}" -Hcrc -Hverify=1 # all files: globbing!
    else
      # check which files already exist
      NFS=''; for F in ${FILES}; do # no quotes! white space delimited list!
	if [[ ! -e "${F}" ]]; then NFS="${NFS} ${F}"; fi; done
      # extract archive
      htar -xpmf "${HTAR}" -Hcrc -Hverify=1 ${NFS}
      MISS=$?
    fi # $GLOB
    # TODO: here some logic to skip already existing files might be useful...
    # for example, existing files could be removed from the file list
  fi
  # verify contents and return result
  return ${MISS}
}

## function to back up one output dataset
function PROCESSDATASET () {
  local DATE="${1}" # the current $TAG, in this context (WRF) the date...
  local ERR=0 # error counter
  ## define datasets
  DATENAME="$DATE" # used in archive file names etc.
  # use globbing expression if asked
  if [[ "${GLOB}" == 'GLOB' ]]; then
      DATE="${DATE}${DATEGLOB}"; fi # GLOB
  # full backup (d01+d02)
  if [[ "${DATASET}" == 'FULL_D12' ]]; then
    local STATIC="static.tgz wrfconst_d01.nc wrfconst_d02.nc" # only on cold start, otherwise skip
    local LOGS="${DATE}_pyWPS.tgz ${DATE}_real.tgz ${DATE}_wrf.tgz"
    local DIAGS="wrfxtrm_d01_${DATE}-01_00:00:00.nc wrfsrfc_d01_${DATE}-01_00:00:00.nc wrfplev3d_d01_${DATE}-01_00:00:00.nc wrfxtrm_d02_${DATE}-01_00:00:00.nc wrfsrfc_d02_${DATE}-01_00:00:00.nc wrfplev3d_d02_${DATE}-01_00:00:00.nc"
    local DYN_D1="wrfdrydyn3d_d01_${DATE}-01_00:00:00.nc"
    local DYN_D2="wrfdrydyn3d_d02_${DATE}-01_00:00:00.nc"
    local MISC_D1="wrfmoist3d_d01_${DATE}-01_00:00:00.nc wrflsm_d01_${DATE}-01_00:00:00.nc wrfrad_d01_${DATE}-01_00:00:00.nc wrfhydro_d01_${DATE}-01_00:00:00.nc wrffdda_d01_${DATE}-01_00:00:00.nc"
    local MISC_D2="wrfmoist3d_d02_${DATE}-01_00:00:00.nc wrflsm_d02_${DATE}-01_00:00:00.nc wrfrad_d02_${DATE}-01_00:00:00.nc wrfhydro_d02_${DATE}-01_00:00:00.nc"
  # full backup for domain 1 (d01)
  elif [[ "${DATASET}" == 'FULL_D1' ]]; then
    unset DYN_D2 MISC_D2
    local STATIC="static.tgz wrfconst_d01.nc" # only on cold start, otherwise skip
    local LOGS="${DATE}_pyWPS.tgz ${DATE}_real.tgz ${DATE}_wrf.tgz"
    local DIAGS="wrfxtrm_d01_${DATE}-01_00:00:00.nc wrfsrfc_d01_${DATE}-01_00:00:00.nc wrfplev3d_d01_${DATE}-01_00:00:00.nc"
    local DYN_D1="wrfdrydyn3d_d01_${DATE}-01_00:00:00.nc"
    local MISC_D1="wrfmoist3d_d01_${DATE}-01_00:00:00.nc wrflsm_d01_${DATE}-01_00:00:00.nc wrfrad_d01_${DATE}-01_00:00:00.nc wrfhydro_d01_${DATE}-01_00:00:00.nc wrffdda_d01_${DATE}-01_00:00:00.nc"
  # only smaller diagnostics (d01+d02)
  elif [[ "${DATASET}" == 'DIAGS_D12' ]]; then
    unset DYN_D1 DYN_D2 MISC_D1 MISC_D2
    local STATIC="static.tgz wrfconst_d01.nc wrfconst_d02.nc" # only on cold start, otherwise skip
    local LOGS="${DATE}_pyWPS.tgz ${DATE}_real.tgz ${DATE}_wrf.tgz"
    local DIAGS="wrfxtrm_d01_${DATE}-01_00:00:00.nc wrfsrfc_d01_${DATE}-01_00:00:00.nc wrfplev3d_d01_${DATE}-01_00:00:00.nc wrfxtrm_d02_${DATE}-01_00:00:00.nc wrfsrfc_d02_${DATE}-01_00:00:00.nc wrfplev3d_d02_${DATE}-01_00:00:00.nc"
  # all 3D fields  (d01+d02)
  elif [[ "${DATASET}" == 'MISC3D_D12' ]]; then
    unset STATIC LOGS DIAGS
    local DYN_D1="wrfdrydyn3d_d01_${DATE}-01_00:00:00.nc"
    local DYN_D2="wrfdrydyn3d_d02_${DATE}-01_00:00:00.nc"
    local MISC_D1="wrfmoist3d_d01_${DATE}-01_00:00:00.nc wrflsm_d01_${DATE}-01_00:00:00.nc wrfrad_d01_${DATE}-01_00:00:00.nc wrffdda_d01_${DATE}-01_00:00:00.nc"
    local MISC_D2="wrfmoist3d_d02_${DATE}-01_00:00:00.nc wrflsm_d02_${DATE}-01_00:00:00.nc wrfrad_d02_${DATE}-01_00:00:00.nc"
  # all 3D dry dynamics  (d01+d02)
  elif [[ "${DATASET}" == 'DYN3D_D12' ]]; then
    unset STATIC LOGS DIAGS MISC_D1 MISC_D2
    local DYN_D1="wrfdrydyn3d_d01_${DATE}-01_00:00:00.nc"
    local DYN_D2="wrfdrydyn3d_d02_${DATE}-01_00:00:00.nc"
  # dry dynamics for domain 1 (d01)
  elif [[ "${DATASET}" == 'MISC3D_D1' ]]; then
    unset STATIC LOGS DIAGS MISC_D2 DYN_D2
    local DYN_D1="wrfdrydyn3d_d01_${DATE}-01_00:00:00.nc"
    local MISC_D1="wrfmoist3d_d01_${DATE}-01_00:00:00.nc wrflsm_d01_${DATE}-01_00:00:00.nc wrfrad_d01_${DATE}-01_00:00:00.nc wrffdda_d01_${DATE}-01_00:00:00.nc"
  # dry dynamics for domain 2 (d02)
  elif [[ "${DATASET}" == 'MISC3D_D2' ]]; then
    unset STATIC LOGS DIAGS MISC_D1 DYN_D1
    local DYN_D2="wrfdrydyn3d_d02_${DATE}-01_00:00:00.nc"
    local MISC_D2="wrfmoist3d_d02_${DATE}-01_00:00:00.nc wrflsm_d02_${DATE}-01_00:00:00.nc wrfrad_d02_${DATE}-01_00:00:00.nc"
  # just log files
  elif [[ "${DATASET}" == 'LOGS' ]]; then
    unset DIAGS MISC_D1 DYN_D1 MISC_D2 DYN_D2
    local STATIC="static.tgz wrfconst_d01.nc wrfconst_d02.nc" # only on cold start, otherwise skip
    local LOGS="${DATE}_pyWPS.tgz ${DATE}_real.tgz ${DATE}_wrf.tgz"
  # return error if dataset not found
  else
    unset DIAGS MISC_D1 DYN_D1 MISC_D2 DYN_D2 STATIC LOGS
    echo
    echo "   >>>   WARNING: dataset ${DATASET} not found! (aborting)   <<<   "
    echo
    return 1
  fi # $DATASET
  # determine if this is a cold start or a restart
  if [[ -e "${SRC}/wrfrst_d01_${DATE}-01_00:00:00" ]]; then
    # restart run: backup restart file
    if [[ -n "${MISC_D1}" ]]; then MISC_D1="${MISC_D1} wrfrst_d01_${DATE}-01_00:00:00"; fi
    if [[ -n "${MISC_D2}" ]]; then MISC_D2="${MISC_D2} wrfrst_d02_${DATE}-01_00:00:00"; fi
    if [[ "${GLOB}" != 'GLOB' ]]; then
      unset STATIC; fi # skip this step, if no globbing is used
    # cold start: backup data tables, constants, and geogrid files
  fi
  echo
  # operation feedback
  echo "   ***   ${MODE} ${DATENAME}   ***   "
  # delete source or not?
  if [[ ${MODE} == 'RETRIEVE' ]]
    then echo " (Overwriting source files!) "
  elif [[ ${RMSRC} == 'RMSRC' ]]
    then echo " ++  Removing source files!  ++ "
    else echo " (leaving source files untouched)   "
  fi
  echo
  ## process file lists (skip empty ones)
  if [[ -n "${STATIC}" ]]; then
    # only execute this for the first step/date (cold start)
    echo '  Static data, WRF constants, and geogrid files (both domains):'
    "${MODE}HTAR" "wrfstatic.tar" "${STATIC}"
    ERR=$(( ${ERR} + $? ))
  fi; if [[ -n "${DIAGS}" ]] || [[ -n "${LOGS}" ]]; then
	echo '  Pressure level and surface fields, log files (both domains):' # short description of archive
	"${MODE}HTAR" "wrfdiags_${DATENAME}.tar" "${DIAGS} ${LOGS}"
	ERR=$(( ${ERR} + $? )) # CHECKHTAR returns the number of missing files as exit code
  fi; if [[ -n "${MISC_D1}" ]]; then
	echo '  Miscellaneous field, including 3D moisture (outer domain):'
	"${MODE}HTAR" "wrfmisc_d01_${DATENAME}.tar" "${MISC_D1}"
	ERR=$(( ${ERR} + $? ))
  fi; if [[ -n "${MISC_D2}" ]]; then
	echo '  Miscellaneous field, including 3D moisture (inner domain):'
	"${MODE}HTAR" "wrfmisc_d02_${DATENAME}.tar" "${MISC_D2}"
	ERR=$(( ${ERR} + $? ))
  fi; if [[ -n "${DYN_D1}" ]]; then
	echo '  3D dry dynamics fields (outer domain):'
	"${MODE}HTAR" "wrfdrydyn_d01_${DATENAME}.tar" "${DYN_D1}"
	ERR=$(( ${ERR} + $? ))
  fi; if [[ -n "${DYN_D2}" ]]; then
	echo '  3D dry dynamics fields (inner domain):'
	"${MODE}HTAR" "wrfdrydyn_d02_${DATENAME}.tar" "${DYN_D2}"
	ERR=$(( ${ERR} + $? ))
  fi
  # check for errors
  if [[ ${ERR} != 0 ]]; then
    echo "   >>>   WARNING: there were ${ERR} errors!   <<<   "
    return 1
  else
    echo "${MODE} ${DATENAME} OK!"
    return 0
  fi
}

## execution

# set up directories
hsi mkdir -p "${DST}"
cd "${SRC}"

# feedback
echo
echo
echo '  Settings'
echo "Operation to perform: MODE=${MODE}"
echo "Delete source files? RMSRC=${RMSRC}"
echo "Verify tarball integrity? VERIFY=${VERIFY}"
echo "Use globbing expressions: GLOB=${GLOB}"
echo '  Dataset'
echo "File sets to work on: DATASET=${DATASET}"
echo "Archiving interval: INTERVAL=${INTERVAL}"
echo '  Data Folders'
echo "Archive folder: DST=${DST}"
echo "Source (disk) folder: SRC=${SRC}"
echo
echo

# if no TAGS are given, use file pattern to guess
if [[ -z "${TAGS}" ]] && [[ -n "${PATTERN}" ]]; then
  echo "Inferring TAGS from pattern: PATTERN=${PATTERN}"
  for T in $( ls *${PATTERN} ); do
    TAGS="${TAGS} ${T%${PATTERN}}"; done # extract $TAG from filename
  echo "TAGS=${TAGS}"
else
  echo "TAGS provided by caller:"
  echo "TAGS=${TAGS}"
fi # if no $TAGS
echo
echo

# set counter
ERRORS=0
OPERATIONS=0
# cycle over monthly output datasets
for TAG in ${TAGS} # use WRF log-files as indicator
do
  time -p PROCESSDATASET ${TAG}
  if [ $? == 0 ]; then OPERATIONS=$(( ${OPERATIONS} + 1 ))
  else ERRORS=$(( ${ERRORS} + 1 )); fi
  echo
  echo '   ==========================================================================   '
  echo
done
hsi -q ls "${DST}"

trap - TERM INT

echo
if [ ${ERRORS} == 0 ]; then
  echo "   <<<   ALL ${OPERATIONS} OPERATIONS OK   >>>   "
  echo
  exit 0
else
  echo "   >>>   WARNING: ${ERRORS} OPERATIONS FAILD OR INCOMPLETE!   <<<   "
  echo "   >>>                 ${OPERATIONS} OPERATIONS OK             <<<   "
  echo
  # /scinet/gpc/bin/exit2msg ${ERRORS} # translate exit codes to human-readable messages
  exit ${ERRORS}
fi
